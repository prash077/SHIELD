"""
SHIELD Configuration
====================
Every configurable value lives here. When switching from Ollama (development)
to Lemonade (AMD Ryzen AI), you only change values in this file.
"""

# â”€â”€â”€ LLM Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Development: Ollama on any machine
# Production:  Lemonade Server on AMD Ryzen AI

LLM_PROVIDER = "ollama"  # "ollama" for dev, "lemonade" for AMD

# Ollama settings (development)
OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_MODEL = "llama3.2:3b"

# Lemonade settings (AMD Ryzen AI production)
LEMONADE_BASE_URL = "http://localhost:8000/api/v1"
LEMONADE_MODEL = "Llama-3.2-3B-Instruct-Hybrid"

# Active settings (auto-selected based on provider)
if LLM_PROVIDER == "ollama":
    LLM_BASE_URL = OLLAMA_BASE_URL
    LLM_MODEL = OLLAMA_MODEL
    LLM_API_KEY = "ollama"  # Ollama doesn't need a real key
else:
    LLM_BASE_URL = LEMONADE_BASE_URL
    LLM_MODEL = LEMONADE_MODEL
    LLM_API_KEY = "lemonade"


# â”€â”€â”€ Whisper / Speech-to-Text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Development: Ollama's Whisper or disable STT
# Production:  Lemonade's Whisper on NPU
STT_ENABLED = False  # Set True when Whisper is available
STT_BASE_URL = LLM_BASE_URL
STT_MODEL = "whisper-large-v3-turbo"


# â”€â”€â”€ RAG Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KNOWLEDGE_BASE_DIR = "knowledge_base"
VECTOR_STORE_DIR = "vector_store"

# Embedding model (runs locally via HuggingFace â€” no API needed)
EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"

# How many knowledge base chunks to retrieve per query
RAG_TOP_K = 5


# â”€â”€â”€ Analysis Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LLM_TEMPERATURE = 0.2      # Low temperature = more consistent analysis
LLM_MAX_TOKENS = 800       # Enough for detailed analysis
SUPPORTED_LANGUAGES = ["english", "hindi", "telugu"]


# â”€â”€â”€ UI Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_TITLE = "SHIELD"
APP_ICON = "ğŸ›¡ï¸"
APP_TAGLINE = "On-Device AI Fraud Detection for Indian UPI Users"

# Network monitor refresh interval (seconds)
NETWORK_MONITOR_INTERVAL = 2


# â”€â”€â”€ Known Cloud AI Endpoints (for network monitor) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# If any of these appear in outbound connections, we flag it
CLOUD_AI_ENDPOINTS = [
    "api.openai.com",
    "api.anthropic.com",
    "api.cohere.ai",
    "generativelanguage.googleapis.com",
    "api.together.xyz",
    "api.groq.com",
    "api.mistral.ai",
    "api.replicate.com",
]
